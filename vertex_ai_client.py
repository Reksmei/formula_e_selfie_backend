# -*- coding: utf-8 -*-
"""Formula E Selfie Backend 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJnZE7xxBs5WXwdQQ358lQKuR49JDZsD
"""

import os
import base64
from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename

import vertexai
from vertexai.generative_models import GenerativeModel, Part

# --- Configuration ---
# Ensure these environment variables are set before running the application.
# You can set them in your terminal before running the script.
# Example:
# export GCP_PROJECT_ID="your-gcp-project-id"
# export GCP_LOCATION="us-central1"

PROJECT_ID = os.environ.get("formula-e-selfie")
LOCATION = os.environ.get("GCP_LOCATION", "us-central1")
MODEL_ID = "gemini-2.5-flash-preview-05-20"

if not PROJECT_ID:
    raise ValueError("GCP_PROJECT_ID environment variable not set. Please set it to your Google Cloud project ID.")

# --- Flask App Initialization ---
app = Flask(__name__)
# In a production environment, you would want to restrict the origins.
# For this example, we allow all origins.
CORS(app)

# --- Vertex AI Initialization ---
vertexai.init(project=PROJECT_ID, location=LOCATION)
model = GenerativeModel(MODEL_ID)
print(f"Vertex AI initialized for project '{PROJECT_ID}' in location '{LOCATION}'")


# --- API Endpoint ---
@app.route("/generate", methods=["POST"])
def generate():
    """
    Handles the image generation request from the frontend.
    """
    print("Received request on /generate")
    # 1. Validate Input
    if 'image' not in request.files:
        return jsonify({"error": "No image file provided."}), 400

    prompt = request.form.get('prompt')
    if not prompt:
        return jsonify({"error": "No prompt provided."}), 400

    image_file = request.files['image']

    # Secure the filename and check for allowed extensions if needed
    filename = secure_filename(image_file.filename)
    print(f"Processing image: {filename} with prompt: '{prompt[:30]}...'")

    try:
        # 2. Prepare Data for Vertex AI
        image_bytes = image_file.read()
        mime_type = image_file.mimetype

        image_part = Part.from_data(data=image_bytes, mime_type=mime_type)
        prompt_part = Part.from_text(prompt)

        # 3. Call Vertex AI
        print("Calling Vertex AI API...")
        response = model.generate_content(
            [prompt_part, image_part],
            generation_config={"response_mime_type": "image/png"} # Requesting PNG output
        )
        print("Received response from Vertex AI.")

        # 4. Process and Send Response
        if not response.candidates:
            raise ValueError("API did not return a valid candidate.")

        # Assuming the first part of the first candidate is the image
        generated_image_part = response.candidates[0].content.parts[0]

        if generated_image_part.mime_type not in ["image/png", "image/jpeg"]:
            raise TypeError("Did not receive an image from the API.")

        # Encode the binary image data to base64
        base64_data = base64.b64encode(generated_image_part.data).decode('utf-8')
        generated_mime_type = generated_image_part.mime_type
        image_data_url = f"data:{generated_mime_type};base64,{base64_data}"

        print("Successfully generated image. Sending response to client.")
        return jsonify({"imageData": image_data_url})

    except Exception as e:
        print(f"An error occurred: {e}")
        # A simple check for safety-related errors from the API response text
        if "safety" in str(e).lower():
            return jsonify({
                "error": "Image generation failed due to safety filters. Please try a different image or prompt."
            }), 500
        else:
            return jsonify({"error": f"An internal server error occurred: {e}"}), 500


# --- Server Start ---
if __name__ == "__main__":
    # Flask runs on port 5000 by default.
    # The host '0.0.0.0' makes it accessible from your network.
    app.run(host="0.0.0.0", port=5000, debug=True)
